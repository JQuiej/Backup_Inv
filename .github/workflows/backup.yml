name: Backup Diario

on:
  schedule:
    - cron: '0 3 * * *'
  workflow_dispatch:

jobs:
  backup_and_upload:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout del cÃ³digo
        uses: actions/checkout@v3

      # 1. Instalar herramientas PostgreSQL
      - name: Instalar herramientas PostgreSQL 17
        run: |
          sudo apt-get install -y wget gnupg2 lsb-release
          sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
          wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
          sudo apt-get update
          sudo apt-get install -y postgresql-client-17

      # 2. Instalar Rclone
      - name: Instalar Rclone
        run: |
          sudo -v ; curl https://rclone.org/install.sh | sudo bash

      # 3. Configurar Rclone
      - name: Configurar Rclone
        env:
          RCLONE_CONF: ${{ secrets.RCLONE_CONF }}
        run: |
          mkdir -p ~/.config/rclone
          echo "$RCLONE_CONF" | base64 --decode > ~/.config/rclone/rclone.conf

      # 4. Generar y Limpiar Backups (Con Python Mejorado)
      - name: Generar Backups y Subir
        env:
          DATABASE_URL: ${{ secrets.SUPABASE_DB_URL }}
        run: |
          DATE=$(date +%Y-%m-%d)
          FILE_SUPABASE="backup-supabase-$DATE.sql"
          FILE_POSTGRES="backup-postgres-clean-$DATE.sql"
          
          echo "ðŸ“¦ Generando versiÃ³n SUPABASE..."
          /usr/lib/postgresql/17/bin/pg_dump "$DATABASE_URL" -f "$FILE_SUPABASE"

          echo "ðŸ§¹ Generando versiÃ³n POSTGRES..."
          /usr/lib/postgresql/17/bin/pg_dump "$DATABASE_URL" --no-owner --no-acl --inserts -n public -f "$FILE_POSTGRES"
          
          # === LIMPIEZA INTELIGENTE ===
          echo " Ejecutando script de limpieza Python..."
          python3 -c "
          import re
          
          filename = '$FILE_POSTGRES'
          
          with open(filename, 'r', encoding='utf-8') as f:
              sql = f.read()
          
          sql = re.sub(r'ALTER TABLE ONLY public\.\w+\s+ADD CONSTRAINT[^;]+REFERENCES auth\.users[^;]*;', '', sql, flags=re.DOTALL)
          
          sql = re.sub(r'^\\restrict.*$', '', sql, flags=re.MULTILINE)
          
          sql = re.sub(r'CREATE EXTENSION[^;]*;', '', sql, flags=re.DOTALL)
          sql = re.sub(r'COMMENT ON EXTENSION[^;]*;', '', sql, flags=re.DOTALL)
          sql = re.sub(r'CREATE SCHEMA[^;]*;', '', sql, flags=re.DOTALL)
          sql = re.sub(r'SELECT pg_catalog\.set_config[^;]*;', '', sql, flags=re.DOTALL)
          
          with open(filename, 'w', encoding='utf-8') as f:
              f.write(sql)
          "

          echo "ðŸ’‰ Inyectando Mocks y Modo RÃ©plica..."
          echo "-- Header Limpio" > header.sql
          
          # Modo rÃ©plica (acepta datos aunque falten referencias)
          echo "SET session_replication_role = 'replica';" >> header.sql
          
          # Mocks para evitar errores de 'no existe esquema'
          echo "CREATE SCHEMA IF NOT EXISTS auth;" >> header.sql
          echo "CREATE SCHEMA IF NOT EXISTS storage;" >> header.sql
          echo "CREATE SCHEMA IF NOT EXISTS extensions;" >> header.sql
          
          # ExtensiÃ³n UUID (Vital para tus PKs)
          echo "CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\" SCHEMA extensions;" >> header.sql
          
          echo "" >> header.sql
          
          # Unir todo
          cat header.sql "$FILE_POSTGRES" > temp.sql && mv temp.sql "$FILE_POSTGRES"
          rm header.sql

          echo "ðŸš€ Subiendo a Google Drive..."
          rclone copy "$FILE_SUPABASE" midrive:Backups
          rclone copy "$FILE_POSTGRES" midrive:Backups
          
          echo "âœ… Â¡Ã‰xito!"
